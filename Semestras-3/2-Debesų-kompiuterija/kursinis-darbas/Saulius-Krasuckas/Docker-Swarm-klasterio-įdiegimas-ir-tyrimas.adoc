= {nbsp}{nbsp}{nbsp}{nbsp}{nbsp}{nbsp}Vilniaus Gedimino technikos universitetas

[.text-center]
== Elektronikos fakultetas

=== Kompiuterijos ir ryšių technologijų katedra

{nbsp}

{nbsp}

{nbsp}

{nbsp}

{nbsp}

{nbsp}

=== Debesų kompiuterija
Modulis ELKRM17304

[.text-center]
== _Docker Swarm_ klasterio įdiegimas ir tyrimas

Kursinis darbas

{nbsp}

{nbsp}

{nbsp}

{nbsp}

{nbsp}

{nbsp}

[.text-right]
**Atliko:** TETfm-20 grupės magistrantas +
                       Saulius Krasuckas +
**Tikrino:** lekt. dr. Liudas Duoba

{nbsp}

{nbsp}

{nbsp}

{nbsp}

{nbsp}

{nbsp}

{nbsp}

VILNIUS, 2022

<<<



{nbsp}

[.text-center]
==== Kursinis darbas

[.text-center]
== _Docker Swarm_ klasterio įdiegimas ir tyrimas


{nbsp}

=== 1. Kursinio darbo užduotis

[.text-left]
* Savarankiškai išstudijuoti _Docker Swarm_ veikimo principus, juos aprašyti
* Sukonfigūruoti _Docker Swarm_ klasterį,
  kurį sudaro ne mažiau trijų kompiuterių / virtualių mašinų (VM)
* Atvaizduoti klasterio konfigūraciją grafiškai (pateikti schemas)
* Klasteryje paleisti _Web_-servisą, veikiantį konteinerių pagrindu.
  Servisas turi būti pasiekiamas.
* Sukurti ne mažiau kaip 3 serviso kopijas (replikas).
  Parodyti, kaip servisai pasiskirsto klasteryje.
* Imituoti vieno iš klasterio elementų gedimą;
  aprašyti / parodyti poveikį servisams.
* Parodyti / atvaizduoti _Web_-serviso pasiekiamumą visuose etapuose.
* Pateikti naudojamas komandas


{nbsp}

=== 2. Pagrindinė dalis

{nbsp}

[.text-left]
==== _Docker Swarm_ veikimo principai

* Savarankiškai išstudijuoti _Docker Swarm_ veikimo principus, juos aprašyti


{nbsp}

[.text-left]
==== _Docker Swarm_ klasterio konfigūravimas

. Infrastruktūrai kuri pasirinkau namie turimą nešiojamąjį kompiuterį su Windows OS.
. Jame įsidiegiau VirtualBox VMM (arba hipervizorių).
. Kaip _Guest OS_ pasirinkau 64-bit **Ubuntu 20.04.3 LTS** Linux distribuciją.
. Pasinaudojau `OSboxes.org` projekto teikiamu įdiegtos OS atvaizdžiu.  <<1>>
. VM kūrimui ir valdymui pasirinkau VirtualBox CLI `VBoxManage` ir MSYS2 įrankį, kuris Windows OS suteikia _*nix_ tipo aplinką.
. Čia susikūriau kelis _Bash_ skriptus:
 - https://github.com/VGTU-ELF/TETfm-20/tree/main/Semestras-3/2-Debes%C5%B3-kompiuterija/kursinis-darbas/Saulius-Krasuckas#:~:text=build%2Dinfra.sh,ubuntu%2Dhostnames.sh[`build-infra.sh`] (_Golden image_ ir atskirų VM formavimui)
 - https://github.com/VGTU-ELF/TETfm-20/blob/main/Semestras-3/2-Debes%C5%B3-kompiuterija/kursinis-darbas/Saulius-Krasuckas/setup-osboxes-ubuntu-20.04.sh[`setup-osboxes-ubuntu-20.04.sh`] (VM tvarkymo eiga)
 - https://github.com/VGTU-ELF/TETfm-20/blob/main/Semestras-3/2-Debes%C5%B3-kompiuterija/kursinis-darbas/Saulius-Krasuckas/osboxes-ubuntu-20.04-changes.sh[`osboxes-ubuntu-20.04-changes.sh`] (pagrindiniai Guest OS tvarkymo veiksmai)
 - https://github.com/VGTU-ELF/TETfm-20/blob/main/Semestras-3/2-Debes%C5%B3-kompiuterija/kursinis-darbas/Saulius-Krasuckas/setup-ubuntu-docker.sh[`setup-ubuntu-docker.sh`] (_Docker_ įdiegimas)
 - https://github.com/VGTU-ELF/TETfm-20/blob/main/Semestras-3/2-Debes%C5%B3-kompiuterija/kursinis-darbas/Saulius-Krasuckas/setup-ubuntu-hostnames.sh[`setup-ubuntu-hostnames.sh`] (individualizuotų mazgo vardų tvarkymas)
. Startavus `build-infra.sh`:
 - Parsisiunčiamas `Ubuntu 20.04.3 (64bit).vdi` atvaizdis.
 - Jo pagrindu sukuriama etaloninė VM.
 - Ji startuojama, ir atliekami pagrindiniai OS tvarkymo veiksmai (SSH raktų tvarkymas, `sudo` perkonfigūravimas, naujinimai, paketų diegimas, perkrovimas, Docker diegimas).
 - VM išjungiama, o disko atvaizdis paruošiamas jungimui prie keleto mašinų (angl. _Multi-attach_).
 - Sukuriamos trys VM pagal bendrą šabloną:
  * 1 GiB RAM, 2 CPU.
  * 1 NIC išėjimui į internetą (angl. _Default route_);
  * 1 NIC Docker klasterio ryšiui (_App_);
  * 1 NIC OAM ryšiui (angl. _Operation, Administration, Maintenance_).
  * Visi NIC gauna adresus iš VBox integruoto DHCP serviso.
  * Kiekvienai VM nustatomas OAM IP adresas.
  * Prie jo prisijungiama automatiškai.
  * `/etc/hosts` faile užregistruojami suteikti IP adresai ir mazgo vardai.
  * Tuomet šie duomenys surenkami į bendrą failą ir padalinimi į visus Guest OS iš eilės.
  * Taip pat patvirtinami SSH ECDSA raktai tarp skirtingų mazgų.
 - Išskyrus atvaizdžio siuntimo laiką, paruošimas trunka apie 65 min.
 - Trys VM paruoštos darbui.
. Rankiniu būdu konfigūruojamas _Docker Swarm mode_ klasteris:


{nbsp}

[.text-left]
==== Klasterio konfigūracija

.(1 pav.) Klasterio mazgų konfigūracija Host OS atžvilgiu.
image::https://raw.githubusercontent.com/VGTU-ELF/TETfm-20/main/Semestras-3/2-Debes%C5%B3-kompiuterija/kursinis-darbas/Saulius-Krasuckas/img/Docker-Swarm-klasterio-konfig%C5%ABracija.svg[width=100%]

{nbsp}

[.text-left]
==== _Web_-serviso startavimas ir tikrinimas

* Klasteryje paleisti _Web_-servisą, veikiantį konteinerių pagrindu.
  Servisas turi būti pasiekiamas.


{nbsp}

[.text-left]
==== Serviso didinimas (plėtimas)

* Sukurti ne mažiau kaip 3 serviso kopijas (replikas).
  Parodyti, kaip servisai pasiskirsto klasteryje.


{nbsp}

[.text-left]
==== Klasterio elemento gedimas ir įtaka

* Imituoti vieno iš klasterio elementų gedimą;
  aprašyti / parodyti poveikį servisams.


{nbsp}

[.text-left]
==== _Web_-serviso pasiekiamumas įvairiuose etapuose

* Parodyti / atvaizduoti _Web_-serviso pasiekiamumą visuose etapuose.


{nbsp}

=== 3. Rezultatų apibendrinimas
[.text-left]
==== {nbsp}

Susikonstravau VM infrastruktūrą VirtuaBox hipervizoriaus (Type II) pagrindu.
Kiekvienai VM skyriau po tris tinklo interfeisus:

. prisijungimui prie interneto (atnaujinimų siuntimams ir kt.)
. aplikacijai / klasterio mazgų ryšiui;
. OS valdymui (OAM).

Sukūriau tris VM, jose pasinaudojau _Docker Swarm Mode_ technologija ir startavau trijų mazgų klasterį:

. _Manager + Worker_;
. _Worker_;
. _Worker_.

Klasteryje _Docker_ konteinerių pagrindu paleidau savo pasirinktą _Web_-servisą `katacoda/docker-http-server`.  Patikrinau jį iš savo kompiuterio: pasiekiamas.

Sukūriau tris serviso replikas.  Patikrinau ir užfiksavau jų pasiskirstymą klasteryje.

Imitavau klasterio elemento gedimą: atjungiau pirmojo mazgo `swarm-n01` klasterinį tinklo interfeisą.

_Manager_ nustojo matyti likusius du mazgus ir perkūrė du jų konteinerius pas save.  Bėda, kad jis pats būtų tapęs nepasiekiamu produkciniam tinklui (NLB ar maršrutizatoriui).  Tačiau per OAM interfeisą visi trys konteineriai buvo pasiekiami.

Tuo tarpu mazgai `swarm-n02` ir `swarm-n03` iškart nustojo atsiliepti į užklausas `80/TCP` portu iš viso, nors jų klasteriniai interfeisai ir tebeveikė.

Po <20 s. jų atsakymai į užklausas atsistatė -- jie jas pradėjo balansuoti tarpusavyje ir grąžindavo jau du skirtingus _Host-id_.

Iš esmės, situacija mano vertinimu atitinka klasterinį _Split-brain_ scenarijų, kai abi klasterio dalys nusprendžia, kad kita pusė nebeveikia, ir bando veikti abi nepriklausomai.

* => Darau išvadą, kad klasteriui paskyrus tiek nedaug mazgų, vertėtų padidinti ne tik _Worker_ skaičių, bet ir _Manager_ skaičių.
+
Priešingu atveju įmanomas pavojus duomenų vientisumui, kai dvi grupės vienu metu keis tuos pačius duomenis, bet kiekviena laikys, kad keičia tik ji pati, tik viena grupė.

Toliau atstačiau tinklo veikimą, ir stebėjau konteinerių būsenas tiek _Worker_ mazguose, tiek _Manager_ mazge.
Netrukus jie pradėjo atsakymuose grąžinti naujus _Host-id_.

Patikrinus pasirodė, kad visi šie _Host-id_ priklauso `swarm-n01` mazge veikiantiems dviems naujiems konteineriams, sukurtiems splito metu.
Ir dabar šiaip paslaugai visos trys replikos veikė būtent šiame mazge.
Konteineriai _Worker_ mazguose išsijungė netrukus po _Manager_ tinklo atstatymo.

Po šito paskirsčiau replikas vėl po lygiai -- po vieną kiekvienam mazgui: `... scale kursinis-web-service=1` ir  `... scale kursinis-web-service=3`.

Ir kai tuo tarpu pilnai išjungiau antrą mazgą, `swarm-n02`, jo replika buvo pakeista nauja replika pirmajame mazge, `swarm-n01`.

Į užklausas abu tebeveikiantys mazgai atsakydavo sėkmingai (`swarm-n01` ir `swarm-n03`).

Mazgą `swarm-n02` vėl įjungus, jis pats sugrįžo į klasterį, tačiau veikiančios replikos pasiliko savo dabartiniuose mazguose (dvi `swarm-n01` ir viena `swarm-n03`).

O štai užklausos į servisą pradėjo veikti jau ir per antrąjį mazgą -- sugrįžęs į klasterį jis įsitraukė į _Routing mesh_ ir _Load-balancing_ mechanizmą.

* => Jei gedimas įvyksta _Worker_ mazge, o ne _Manager_, įtaka paslaugai beveik nejuntama.
+
Paslaugos replikų skaičius atstatomas (sukuriamos trūkstamosios) ilgiausiai po ~ 5 s.


{nbsp}

=== 4. Naudota literatūra
[.text-left]
==== {nbsp}

**[[[1]]]** https://www.osboxes.org/ubuntu/#ubuntu-20-04-3-info[OSboxes > VirtualBox Images > Ubuntu > Ubuntu 20.04.3 Focal Fossa]


https://docs.docker.com/engine/swarm/swarm-tutorial/[Docker docs {nbsp} > {nbsp} Run your app in production {nbsp} > {nbsp} Getting started with swarm mode (tutorial)]

https://www.katacoda.com/courses/docker-orchestration[Learn Docker Orchestration / Swarm Mode using Interactive Browser-Based Scenarios]

https://www.katacoda.com/courses/docker-orchestration/getting-started-with-swarm-mode[Getting Started With Swarm Mode]

https://www.katacoda.com/courses/docker-orchestration/create-overlay-networks[Create Overlay Network]

https://www.katacoda.com/courses/docker-orchestration/load-balance-service-discovery-swarm-mode[Load Balance and Service Discover in Swarm Mode]

https://www.katacoda.com/courses/docker-orchestration/rolling-updates-services-swarm-cluster[Apply Rolling Updates Across Swarm Cluster]

https://www.katacoda.com/courses/docker-orchestration/healthcheck[Add Healthcheck for Containers]

https://www.katacoda.com/courses/docker-orchestration/deploy-swarm-services-with-compose[Deploy Swarm Services with Compose v3]

https://www.katacoda.com/courses/docker-orchestration/maintenance-mode-for-swarm[Enable Maintenance Mode for a Swarm Node]

https://blog.jayway.com/2015/11/25/simple-clustering-with-docker-swarm-and-nginx/[Simple Clustering with Docker Swarm and Nginx]


{nbsp}

<<<

=== 5. Priedai
[.text-left]

(Schemos, kodas)

